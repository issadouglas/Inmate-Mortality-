{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a60655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape years from 2017-2018 to 2022- 2023\n",
    "\n",
    "base_url = \"http://www.dc.state.fl.us/pub/mortality/\"\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}\n",
    "\n",
    "def get_urls_from_single_page(date_url):\n",
    "    page = requests.get(date_url, headers=hdr)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    url_list = []\n",
    "    \n",
    "    year_list = soup.find_all('th', scope ='row')\n",
    "    for year in year_list:\n",
    "        url_list.append(year.find('a').attrs['href'])\n",
    "        \n",
    "    return url_list\n",
    "\n",
    "url_list = get_urls_from_single_page(base_url)\n",
    "\n",
    "#print(url_list)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89162736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape name, dcNumber, dateOfDeath, institution, mannerOfDeath\n",
    "\n",
    "list_url = \"http://www.dc.state.fl.us/pub/mortality/2022-2023.html\"\n",
    "\n",
    "def scrape_one_incident(incident_url):\n",
    "    response = requests.get(incident_url, headers=hdr)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    rows = soup.find(\"table\", {\"class\": \"small\"}).find_all(\"tr\")\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all(\"td\")\n",
    "        name = cells[0].text.strip()\n",
    "        dc_number = cells[1].text.strip()\n",
    "        date_of_death = cells[2].text.strip()\n",
    "        institution_name = cells[3].text.strip()\n",
    "        manner_of_death = cells[4].text.strip()\n",
    "        data.append({'name': str(name), 'dc_number': str(dc_number), 'date_of_death': str(date_of_death), 'institution_name':str(institution_name), 'manner_of_death':str(manner_of_death)})\n",
    "    return data\n",
    "\n",
    "#test url\n",
    "#url_list = [list_url]\n",
    "\n",
    "incident_data = []\n",
    "for url in url_list:\n",
    "    data = scrape_one_incident(\"http://www.dc.state.fl.us/pub/mortality/\" + url)\n",
    "    incident_data.extend(data)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the list of all incident data\n",
    "#print(incident_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14858b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL year urls\n",
    "\n",
    "def get_urls_from_single_page(year_url):\n",
    "    page = requests.get(year_url, headers=hdr)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    url_list = []\n",
    "    \n",
    "    inmate_list = soup.find_all('table', class_ ='small')\n",
    "    for inmate in inmate_list:\n",
    "        atags = inmate.find_all('a')\n",
    "        link_list = []\n",
    "        for a in atags: \n",
    "            link_list.append(a.attrs['href'])\n",
    "        url_list.extend(link_list)\n",
    "        \n",
    "    return url_list\n",
    "\n",
    "inmateYearUrls_list = []\n",
    "for url in url_list:\n",
    "    data = get_urls_from_single_page(\"http://www.dc.state.fl.us/pub/mortality/\" + url)\n",
    "    inmateYearUrls_list.extend(data)\n",
    "    \n",
    "\n",
    "\n",
    "#print(inmateYearUrls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape name, race, sex, birth date, custody\n",
    "\n",
    "#test_url = \"http://www.dc.state.fl.us/OffenderSearch/detail.aspx?Page=Detail&DCNumber=Y53732&TypeSearch=IR\"\n",
    "\n",
    "def scrape_one_inmate(inmate_url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(inmate_url, headers=hdr)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    name = \"\"\n",
    "    name_tags = soup.find_all('th', scope='row')\n",
    "    for tag in name_tags:\n",
    "        if \"Name\" in tag.text:\n",
    "            name = tag.find_next_sibling('td').text.strip()\n",
    "            break\n",
    "    # add a placeholder string if name is empty\n",
    "    if not name:\n",
    "        name = \"Unknown\"\n",
    "\n",
    "    race = \"\"\n",
    "    race_tags = soup.find_all('th', scope='row')\n",
    "    for tag in race_tags:\n",
    "        if \"Race\" in tag.text:\n",
    "            race = tag.find_next_sibling('td').text.strip()\n",
    "            break\n",
    "    # add a placeholder string if race is empty\n",
    "    if not race:\n",
    "        race = \"Unknown\"\n",
    "\n",
    "    sex = \"\"\n",
    "    sex_tags = soup.find_all('th', scope='row')\n",
    "    for tag in sex_tags:\n",
    "        if \"Sex\" in tag.text:\n",
    "            sex = tag.find_next_sibling('td').text.strip()\n",
    "            break\n",
    "    # add a placeholder string if sex is empty\n",
    "    if not sex:\n",
    "        sex = \"Unknown\"\n",
    "\n",
    "    bday = \"\"\n",
    "    bday_tags = soup.find_all('th', scope='row')\n",
    "    for tag in bday_tags:\n",
    "        if \"Birth Date\" in tag.text:\n",
    "            bday = tag.find_next_sibling('td').text.strip()\n",
    "            break\n",
    "    # add a placeholder string if bday is empty\n",
    "    if not bday:\n",
    "        bday = \"Unknown\"\n",
    "\n",
    "    custody = \"\"\n",
    "    custody_tags = soup.find_all('th', scope='row')\n",
    "    for tag in custody_tags:\n",
    "        if \"Custody\" in tag.text:\n",
    "            custody = tag.find_next_sibling('td').text.strip()\n",
    "            break\n",
    "    # add a placeholder string if custody is empty\n",
    "    if not custody:\n",
    "        custody = \"Unknown\"\n",
    "\n",
    "    data = {'name': str(name), 'race': str(race), 'sex': str(sex), 'bday':str(bday), 'custody':str(custody)}\n",
    "\n",
    "    return data\n",
    "\n",
    "inmateBio_list = []\n",
    "for url in inmateYearUrls_list:\n",
    "    data = scrape_one_inmate(\"http://www.dc.state.fl.us/\" + url)\n",
    "    inmateBio_list.append(data) \n",
    "\n",
    "#print(inmateBio_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv():\n",
    "    filename = \"fl_inmates_mortality_info.csv\" \n",
    "    f = open(filename, 'w', newline='', encoding='utf-8')\n",
    "    writer = csv.writer(f)\n",
    "    fieldnames = ['name', 'dc_number', 'date_of_death', 'institution_name', 'manner_of_death']\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "    all_inmate_data = []\n",
    "    for incident in incident_data:\n",
    "        writer.writerow([incident['name'], incident['dc_number'], incident['date_of_death'], incident['institution_name'], incident['manner_of_death']])\n",
    "\n",
    "\n",
    "    f.close()\n",
    "\n",
    "write_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv():\n",
    "    filename = \"fl_inmates_mortality_bio.csv\" \n",
    "    f = open(filename, 'w', newline='', encoding='utf-8')\n",
    "    writer = csv.writer(f)\n",
    "    fieldnames = ['name', 'race', 'sex', 'bday', 'custody']\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "    for inmate in inmateBio_list:\n",
    "        writer.writerow([inmate['name'], inmate['race'], inmate['sex'], inmate['bday'], inmate['custody']])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "write_csv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de61f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
